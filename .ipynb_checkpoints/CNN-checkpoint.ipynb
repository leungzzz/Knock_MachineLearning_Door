{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "\n",
    "前面所讲的都是fully connected NN, 如果要把NN应用到具体的目标上，比如图像，且着重考虑它的特性，NN能被简化么？\n",
    "\n",
    "首先图像都有哪些特性,考虑下面这幅图？\n",
    "\n",
    "![](./ml_png/7_image.jpg)\n",
    "\n",
    "①. 图像中感兴趣的pattern通常要比整幅图像要小得多，比如鸟儿身上的纹理、鸟喙等。亦即代表我们不需要让一个neuron“辐射”一整幅图像像素来找出这些局部性特征。换而言之，只需要让一个neuron连接到局部region而非整张图像即可感知图像的结构，这样还能大幅压缩params的总参数。\n",
    "\n",
    "②. 相同的pattern可能会出现在多幅图像的不同位置，如果针对这些不同位置的相类似的patterns分别要使用不同的weight来加以检测，那将导致资源浪费。换而言之，可以共用同一组weight参数来发现这些patterns.\n",
    "\n",
    "③. 下采样像素并不会造成目标在整幅图像中的位置、信息发生不可辨别的变化。换而言之，可通过下采样来使图像变小，这样NN就可以用更少的params来处理images.\n",
    "\n",
    "综上所述，有如下的Whole CNN方案：\n",
    "\n",
    "$$\n",
    "\\boxed{input} \\rightarrow \\boxed{Convolution} \\rightarrow  \\boxed{Maxpooling}  \\rightarrow \\boxed{Convolution}  \\rightarrow  \\boxed{Maxpooling} \\rightarrow  \\dots  \\rightarrow \\boxed{Flattern} \\rightarrow \\boxed{Fully \\  connected \\ feedforward \\ network} \\rightarrow \\boxed{output}\n",
    "$$\n",
    "\n",
    "![](./ml_png/7_the_whole_cnn.png)\n",
    "\n",
    "其中图像特性的①②与Convolution相关、③与maxpooling相关。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN-convolution\n",
    "\n",
    "要素：image、filters(Matrices)\n",
    "\n",
    "其中filters中的参数是network待学习的参数。有如下filters\n",
    "\n",
    "$$\\left[ \\begin{array}{ccc}\n",
    "1 & -1 & -1 \\\\\n",
    "-1 & 1 & -1 \\\\\n",
    "-1 & -1 & 1 \\\\\n",
    "\\end{array}\\right]、\n",
    "\\left[\\begin{array}{ccc}\n",
    "-1 & 1 & -1 \\\\\n",
    "-1 & 1 & -1 \\\\\n",
    "-1 & 1 & -1 \\\\\n",
    "\\end{array}\\right]、\\dots\n",
    "$$\n",
    "\n",
    "其中的每一个filter都是用于检测一个$3\\times 3$大小的pattern.这是property1.\n",
    "\n",
    "Property2, 图像的不同位置可能出现相同的patterns。\n",
    "\n",
    "![](./ml_png/7_p2.png)\n",
    "\n",
    "如上图是同一个filter检测出这些patterns，当使用多个不同的filter时，可以按需查找不同类型的pattern.如下图为查找包含3个像素的竖直线段。由多个filters组成的matrices构成了tensor，被称为feature map，它包含了input的基本结构。\n",
    "\n",
    "![](./ml_png/7_p2_2.png)\n",
    "\n",
    "此处要分清：filter的通道维数应该与image的通道维数保持一致；filter的个数决定了feature map的通道个数。比如以彩色RGB图像为例，完成一次convolution，那么它的每个filter的通道数为3.使用了3个filters，那么它们的卷积结果就为通道数目为3的feature map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected V.S Convolution\n",
    "\n",
    "FC就是每个input值（图像中的所有单个像素值）都与下一层Layer的所有neuron相连。如下图，为方便理解，先把图像按一定顺序排列为向量形式。\n",
    "\n",
    "![](./ml_png/7_fc.png)\n",
    "\n",
    "而在convolution中，则是部分input值与下一层layer的neuron通过filter中的params相连，并且这些params是可以传递给下一组input的。如下图\n",
    "\n",
    "![](./ml_png/7_fc_conv_comp.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN-maxpooling\n",
    "\n",
    "![](./ml_png/7_cnn_maxpooling.png)\n",
    "\n",
    "以上图示表明，maxpooling最大池化层就是先选定一个$m \\times m$方形区域，然后选定这个区域内的最大像素值作为该区域的替代值。最终图像的channel不变，长、宽值则变为原来的$\\frac{1}{m}$.\n",
    "\n",
    "#### CNN - Convolution + maxpooling\n",
    "\n",
    "![](./ml_png/7_conv_maxpooling.png)\n",
    "\n",
    "经过Conv+maxp后，新的（且比原来更小的）图像诞生了。新的图像的channel就是conv中所用的filters的个数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN - Flatten\n",
    "\n",
    "Flatten就是将每个channel的像素延展为一个列向量，然后将它们拼接起来组成单个大的列向量。如图所示。\n",
    "\n",
    "![](./ml_png/7_flatten.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为maxp中无待学习的参数，接下来计算CNN model中每个conv+maxp对中单个conv所包含的params的数目。如下图：\n",
    "\n",
    "![](./ml_png/7_params.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入大小为$1\\times 28 \\times 28$的图像，经过第一个Convolution + Map pooling后，输出大小为$25\\times 13 \\times 13$的图像。那么在上述的$3 \\times 3$的filters中，单个filter的参数为9，由于输出的channels为25，因此一共用了25个这样的$3\\times 3$的filters。故第一个conv块共包含了$9\\times 25$个params. 同理，由于经过第二个conv模块处理后输出50个channels,而原来的每个filter的参数个数为$25 \\times 9 \\times 9$，则第二个conv模块共使用了$50 \\times 25 \\times 9 \\times 9$个params。后面的Flatten不涉及参数运算，只是将channels进行延伸。最后的Fully connected NN所使用的参数与Layers个数和每层layer中使用的neurons有关。\n",
    "\n",
    "上面的结构在training、testing、BP等与前面的DNN基本类似，不同的地方主要为：1,原来的dnn输入是展开为一个vector,但在CNN中是直接输入一个包含长宽的、多个channel的vector,这个vector常常被称为tensor. 2. 第二个不同的地方在于，它的结构比DNN稍微复杂一些，因为CNN的结构由多个conv层、maxpooling层、flatten等组成，而DNN只是由最简单的全连接、activation组成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does CNN learn?\n",
    "\n",
    "现在已经定义了完整的CNN结构、介绍了他们内部的卷积层、最大池化层、flatten层等。在前面的讨论中，可知道CONV的filter是可以具体感知某一种结构的，比如右倾斜的线段、竖直线段等。可是回到CNN结构的时候，应该如何判断每个filter的作用呢？\n",
    "\n",
    "当input是$1\\times 28\\times 28$时，filter是$3\\times 3$的大小，这样的filter理解起来还好。只需要观察它内部的值，可模糊估计它的作用。可是中间layer的filter，其channel有多个而非1个，如下图第二个conv用了50个大小为$3\\times 3 \\times 25$大小的filter,那么这50个filter的作用又分别是什么呢？即使这次也给定了它们的weight,但并不会像第一个conv中使用的$1\\times 3\\times 3$的filter那样易于分析。\n",
    "\n",
    "![](./ml_png/7_cnn_learn.png)\n",
    "\n",
    "于是转而从另一个角度进行分析。既然目标是分析CNN学习的内容，而CNN负责学习内容的关键是filters，即分析每个filter的作用是分析CNN作用的核心。我们要分析filter的作用，相当于去弄清楚它处理input中哪一类结构最灵敏。比如，一条流水线上需要专门拧螺丝、切割圆、磨棱角等工作的3种工人。来了一批新入职员工，为了测试他们擅长的工作，分别让他们一一尝试这三类工作。结果发现工人A拧螺丝拧得最紧，而在完成其他两类工作时完成度相对较低。那么我们就倾向于认为他是拧螺丝的好手，他的作用是在流水线上拧螺丝。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
